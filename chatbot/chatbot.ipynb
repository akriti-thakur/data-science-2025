{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e66a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string  # for punctuation removal\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631c2807",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a350cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/atwal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/atwal/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/atwal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/atwal/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7dcb960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 54\n",
      "Total words: 1475\n"
     ]
    }
   ],
   "source": [
    "with open(\"panjabdcsa.txt\", 'r', errors='ignore') as f:\n",
    "    raw = f.read().lower()\n",
    "\n",
    "sent_tokens= nltk.sent_tokenize(raw)\n",
    "word_tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "print(\"Total sentences:\", len(sent_tokens))\n",
    "print(\"Total words:\", len(word_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6978f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd67d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"hello\", \"I am glad you are talking to me!\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9ac856",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_idx = None\n",
    "\n",
    "# Response function\n",
    "def response(user_response):\n",
    "    global last_idx\n",
    "    robo_response = ''\n",
    "    sent_tokens.append(user_response)\n",
    "\n",
    "    # TF-IDF\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "\n",
    "    if req_tfidf == 0:\n",
    "        robo_response = \"Hmm... I am not sure about that. Could you ask differently?\"\n",
    "        last_idx = None\n",
    "    else:\n",
    "        last_idx = idx\n",
    "        robo_response = \"Hereâ€™s what I found: \"+ sent_tokens[idx]\n",
    "\n",
    "    sent_tokens.remove(user_response)\n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbffd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_me_more():\n",
    "    global last_idx\n",
    "    if last_idx is not None and last_idx + 1 < len(sent_tokens):\n",
    "        last_idx += 1\n",
    "        return \"Sure! Here's more: \" + sent_tokens[last_idx]\n",
    "    else:\n",
    "        return \"I donâ€™t have more details on that right now.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d687a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! I am UniBot ðŸ¤–. I can answer your queries about Panjab University.\n",
      "Type 'bye' to exit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/data/python/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hereâ€™s what I found: panjab university | brief history and present infrastructure\n",
      "-------------------------------------------------------------\n",
      "- one of the oldest universities in india, the panjab university (pu) initiated at lahore in 1882, has a long tradition of pursuing excellence in teaching and research in science and technology, humanities, social sciences, performing arts and sports.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/data/python/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Sure! Here's more: the university supports excellence and innovation in academic programmes, promotes excellence in research, scholarship and teaching.\n",
      "Chatbot: Hereâ€™s what I found: department of computer science & applications (dcsa) | overview\n",
      "---------------------------------------------------------------\n",
      "- the computer culture at the panjab university dates back to 1966. an independent centre for computer science and applications (now a full fledged department) was set-up in 1983. the department aims at ingraining the spirit of ingenuity, innovativeness and technical competence in the students through rigorous competition and regular guidance.\n",
      "Chatbot: Hereâ€™s what I found: master of computer applications (mca) (2 years full time course) in self financed mode and master of science (computer science) under the framework of the hon's school (02 years full time course).\n",
      "Chatbot: Hereâ€™s what I found: - research lab with specialized computing systems.\n",
      "Chatbot: Hereâ€™s what I found: contact us\n",
      "----------\n",
      "anuj sharma\n",
      "chairperson\n",
      "department of computer science & applications\n",
      "top floor\n",
      "c.i.l.\n",
      "Chatbot: Goodbye! Take care.\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"Chatbot: Hi! I am UniBot ðŸ¤–. I can answer your queries about Panjab University.\\nType 'bye' to exit.\")\n",
    "\n",
    "while(flag):\n",
    "    user_response = input(\"You: \").lower()\n",
    "\n",
    "    if user_response != 'bye':\n",
    "        if user_response in ('thanks', 'thank you'):\n",
    "            print(\"Chatbot: You're welcome!\")\n",
    "        elif \"tell me more\" in user_response:\n",
    "            print(\"Chatbot:\", tell_me_more())\n",
    "        elif greeting(user_response) is not None:\n",
    "            print(\"Chatbot:\", greeting(user_response))  \n",
    "        else:\n",
    "            print(\"Chatbot:\", response(user_response))\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Chatbot: Goodbye! Take care.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
